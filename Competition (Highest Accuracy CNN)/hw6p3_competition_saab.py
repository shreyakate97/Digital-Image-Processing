# -*- coding: utf-8 -*-
"""Homework 6_569.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JOgPloHHiwWIleki0JtdLyHey-Fvo83S
"""

!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/pixelhop2.py
!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/cross_entropy.py
!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/cwSaab.py
!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/saab.py
!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/lag.py
!wget https://raw.githubusercontent.com/USC-MCL/EE569_2020Spring/master/llsr.py

import numpy as np
import time

from keras.datasets import cifar10
from keras.utils.np_utils import to_categorical

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

X_train = X_train/255
X = X_train[0:10000,:,:,:]

nti = 50000

from skimage.util import view_as_windows
import skimage.measure
from skimage.measure import block_reduce
def n_shrink(data,shrink_arg):
    win = shrink_arg['win']
    stride = shrink_arg['stride']
    ch = data.shape[-1]

    data1 = view_as_windows(data, (1,win,win,ch), (1,stride,stride,ch))
    data1 = data1.reshape(data1.shape[0], data1.shape[1], data1.shape[2], -1)

    data2 = block_reduce(data1,block_size=(1,2,2,1),func=np.max)
    return data2 #.reshape(data1.shape[0], data1.shape[1], data1.shape[2], -1)

def Concat(X, concatArg):
    return X

SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'useDC':True, 'batch':None, 'cw':False},
              {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True},
              {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True},
              {'num_AC_kernels':-1, 'needBias':True, 'useDC':True, 'batch':None, 'cw':True}]

shrinkArgs = [{'func':n_shrink, 'win':3, 'stride':1},
              {'func': n_shrink, 'win':3, 'stride':1},
              {'func': n_shrink, 'win':3, 'stride':1},
              {'func': n_shrink, 'win':3, 'stride':1}]

concatArg = {'func':Concat}

"""Module 1"""

start = time.time()

    from pixelhop2 import Pixelhop2
    output = []
    p2 = Pixelhop2(depth=4, TH1=0.001, TH2=0.0001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)
    p2.fit(X)

    end = time.time()

    print('Time for Module 1:',(end-start))

import pickle
filename1 = 'p2.sav'
pickle.dump(p2, open(filename1, 'wb'))

import pickle

phop = pickle.load(open('/content/p2.sav', 'rb'))

X_train[0:nti].shape

"""# Module 2"""



# output[3].shape

start = time.time()
output = p2.transform(X_train[0:nti])
print(output[0].shape,output[1].shape,output[2].shape)

from cross_entropy import Cross_Entropy

X_reshape0 = output[0].reshape(len(output[0]), -1,output[0].shape[-1])
X_reshape1 = output[1].reshape(len(output[1]), -1,output[1].shape[-1])
X_reshape2 = output[2].reshape(len(output[2]), -1,output[2].shape[-1])
X_reshape3 = output[3].reshape(len(output[3]), -1,output[3].shape[-1])

kce = Cross_Entropy(num_class=10, num_bin=5)

kce_fd0 = np.zeros(X_reshape0.shape[-1])
kce_fd1 = np.zeros(X_reshape1.shape[-1])
kce_fd2 = np.zeros(X_reshape2.shape[-1])
kce_fd3 = np.zeros(X_reshape3.shape[-1])

for k in range(X_reshape0.shape[-1]):
        kce_fd0[k] = kce.KMeans_Cross_Entropy(X_reshape0[:,:,k].reshape(X_reshape0.shape[0],-1), y_train[0:nti])
print('finished 0')

for k in range(X_reshape1.shape[-1]):
        kce_fd1[k] = kce.KMeans_Cross_Entropy(X_reshape1[:,:,k].reshape(X_reshape1.shape[0],-1), y_train[0:nti])
print('finished 1')
for k in range(X_reshape2.shape[-1]):
        kce_fd2[k] = kce.KMeans_Cross_Entropy(X_reshape2[:,:,k].reshape(X_reshape2.shape[0],-1), y_train[0:nti])
print('finished 2')
for k in range(X_reshape3.shape[-1]):
        kce_fd3[k] = kce.KMeans_Cross_Entropy(X_reshape3[:,:,k].reshape(X_reshape3.shape[0],-1), y_train[0:nti])
print('finished 3')


fd0 = []
fd1 = []
fd2 = []
fd3 = []
for k in range(X_reshape0.shape[-1]):
  fd0.append([k, kce_fd0[k]])

for k in range(X_reshape1.shape[-1]):
  fd1.append([k, kce_fd1[k]])

for k in range(X_reshape2.shape[-1]):
  fd2.append([k, kce_fd2[k]])
for k in range(X_reshape3.shape[-1]):
  fd3.append([k, kce_fd3[k]])

fd0_sorted = sorted(fd0,key=lambda x: x[1])
fd1_sorted = sorted(fd1,key=lambda x: x[1])
fd2_sorted = sorted(fd2,key=lambda x: x[1])
fd3_sorted = sorted(fd3,key=lambda x: x[1])

fd0_ns = fd0_sorted[0:1000]
fd1_ns = fd1_sorted[0:1000]
fd2_ns = fd2_sorted[0:1000]
fd3_ns = fd3_sorted[0:1000]


f_number0 = [i[0] for i in fd0_ns]
f_number1 = [i[0] for i in fd1_ns]
f_number2 = [i[0] for i in fd2_ns]
f_number3 = [i[0] for i in fd3_ns]

from lag import LAG
from llsr import LLSR as myLLSR

lag = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=5, learner=myLLSR(onehot=False))
lag.fit(X_reshape0[:,:,f_number0].reshape(X_reshape0.shape[0],-1), y_train[0:nti])

lag1 = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=5, learner=myLLSR(onehot=False))
lag1.fit(X_reshape1[:,:,f_number1].reshape(X_reshape1.shape[0],-1), y_train[0:nti])

lag2 = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=5, learner=myLLSR(onehot=False))
lag2.fit(X_reshape2[:,:,f_number2].reshape(X_reshape2.shape[0],-1), y_train[0:nti])

lag3 = LAG(encode='distance', num_clusters=[5,5,5,5,5,5,5,5,5,5], alpha=5, learner=myLLSR(onehot=False))
lag3.fit(X_reshape3[:,:,f_number3].reshape(X_reshape3.shape[0],-1), y_train[0:nti])
end = time.time()
print('Module 2:',(end-start))

output[3].shape

y_train.shape

"""Module 3"""

start = time.time()
lag_output_0 = lag.transform(X_reshape0[:,:,f_number0].reshape(X_reshape0.shape[0],-1))
lag_output_1 = lag1.transform(X_reshape1[:,:,f_number1].reshape(X_reshape1.shape[0],-1))
lag_output_2 = lag2.transform(X_reshape2[:,:,f_number2].reshape(X_reshape2.shape[0],-1))
lag_output_3 = lag3.transform(X_reshape3[:,:,f_number3].reshape(X_reshape3.shape[0],-1))


lag_concat = np.concatenate((lag_output_0,lag_output_1,lag_output_2,lag_output_3),axis=1)

Xt = X_test/255
#testing
output_t = p2.transform(Xt)
print(output_t[0].shape,output_t[1].shape,output_t[2].shape,output_t[3].shape)

X_reshape0_t = output_t[0].reshape(len(output_t[0]), -1,output_t[0].shape[-1])
X_reshape1_t = output_t[1].reshape(len(output_t[1]), -1,output_t[1].shape[-1])
X_reshape2_t = output_t[2].reshape(len(output_t[2]), -1,output_t[2].shape[-1])
X_reshape3_t = output_t[3].reshape(len(output_t[3]), -1,output_t[3].shape[-1])

lag_output_0_t = lag.transform(X_reshape0_t[:,:,f_number0].reshape(X_reshape0_t.shape[0],-1))
lag_output_1_t = lag1.transform(X_reshape1_t[:,:,f_number1].reshape(X_reshape1_t.shape[0],-1))
lag_output_2_t = lag2.transform(X_reshape2_t[:,:,f_number2].reshape(X_reshape2_t.shape[0],-1))
lag_output_3_t = lag3.transform(X_reshape3_t[:,:,f_number3].reshape(X_reshape3_t.shape[0],-1))

lag_concat_t = np.concatenate((lag_output_0_t,lag_output_1_t,lag_output_2_t,lag_output_3_t),axis=1)
print(lag_concat_t.shape)

from sklearn.ensemble import RandomForestClassifier
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
model = RandomForestClassifier( max_depth = 30, n_estimators = 200, n_jobs=-1)

model.fit(lag_concat,y_train[0:nti].ravel())

rfc_predict = model.predict(lag_concat)
print('train accuracy:',accuracy_score(y_train[0:nti].ravel(), rfc_predict))
pred = model.predict(lag_concat_t)
print('test accuracy:',accuracy_score(y_test, pred))

end = time.time()
print('Module 3:',(end - start))
